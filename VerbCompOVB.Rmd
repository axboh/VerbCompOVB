---
title: "Verb Complementation in WE"
author: "Axel Bohmann"
date: "15 Dezember 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load data

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r load-packages, message=FALSE, warning=FALSE}
library(dotwhisker)
library(dplyr)
library(tidyverse)
library(glmmTMB)
library(broom.mixed)
library(ModelMetrics)
library(MASS)
library(egg)
library(ggpubr)
library(ggdendro)
library(vegan)
```


```{r load-data, message=FALSE, warning=FALSE}
VComp <- read.csv("VComps_annotated_manual_reduce_analysis.csv")
VComp <- VComp %>%
  filter(lemmaComp!="xxx")
VComp$lemmaComp <- factor(VComp$lemmaComp)
VComp$complpattern <- factor(VComp$complpattern)
VComp$country<- factor(VComp$country)
VComp <- within(VComp, country <- relevel(country, ref = "GB"))
```

### Find categorical versus variable contexts:

```{r reduce-data, message=FALSE, warning=FALSE}
prop.table(xtabs(~ complpattern + lemmaMatrix, data=VComp), 2)
### We keep all verbs that show some variation. Only exclude case: dare
VComp <- VComp %>%
  filter(!lemmaMatrix %in% c("avoid", "dare"))
VComp_red <- VComp %>%
  filter(!lemmaMatrix %in% c("avoid", "dare", "afford", "choose", "expect", 
                             "help", "intend", "offer", "pretend", "try"))
prop.table(xtabs(~ complpattern + negation, data=VComp), 2)
### Only four items for multiple negation, let's drop that:
VComp <- VComp %>%
  filter(negation != "multiple")
prop.table(xtabs(~ complpattern + voiceMatrix, data=VComp), 2)
# fine
prop.table(xtabs(~ complpattern + tenseMatrix, data=VComp), 2)
# fine
prop.table(xtabs(~ complpattern + aspectMatrix, data=VComp), 2)
# progressive takes to-complement in 99% of all cases.
# Let's also exclude this context as a (near-)categorical one.
VComp <- VComp %>% filter(aspectMatrix!="progressive")
```

## Fitting the best model without Dimension scores.

```{r full-model-no-register, message=FALSE, warning=FALSE}
noreg_full  <- glmmTMB(complpattern ~ country + negation + voiceMatrix + tenseMatrix +
                           matrixVerbType + matrixVerbSem + #aspectMatrix + 
                           compVerbType + compVerbSem +
                           (1|lemmaMatrix) + (1|lemmaComp), 
                          data=VComp, family=binomial)
```

We step down from this full model, using likelihood ration tests. Not all steps shown here, just the final model selected as the minimal adequate one given our initial set of predictors:

```{r best-model-no-register, message=FALSE, warning=FALSE}
noreg_red  <- glmmTMB(complpattern ~ country + tenseMatrix +
                         compVerbType + compVerbSem +
                         (1|lemmaMatrix) + (1|lemmaComp), 
                       data=VComp, family=binomial)
noreg <- noreg_red
Preds <- predict(noreg, type = 'response')
auc(VComp$complpattern, Preds)
## This gives and AUC of 0.9190214. This will be our baseline to compare the models.
```

#### Fitting the best model with dimension scores:

```{r full-model-register, message=FALSE, warning=FALSE}
reg_full  <- glmmTMB(complpattern ~ country + negation + voiceMatrix + tenseMatrix +
                         matrixVerbType + matrixVerbSem + 
                         compVerbType + compVerbSem +
                         PA1 + PA2 + PA3 + PA4 + PA5 + PA6 + PA7 + PA8 + PA9 + PA10 +
                         (1|lemmaMatrix) + (1|lemmaComp), 
                       data=VComp, family=binomial)
```

Again, stepping down from the full model and using direct model comparison via LRT.
The winner is:

```{r best-model-register, message=FALSE, warning=FALSE}
reg_reduced2 <- glmmTMB(complpattern ~ country + tenseMatrix +
                         compVerbType + compVerbSem +
                         PA1 + PA2 + PA4 + PA5 + PA9 + PA10 +
                         (1|lemmaMatrix) + (1|lemmaComp), 
                       data=VComp, family=binomial)

### Reducing further does not improve the model

reg <- reg_reduced2
Preds <- predict(reg, type = 'response')
auc(VComp$complpattern, Preds)
## Value of 0.924 is only marginally better than without register, but it is better.
```

### Comparing the best models with and without register

```{r best-model-comparison, message=FALSE, warning=FALSE}
anova(reg, noreg)
AIC(reg)
AIC(noreg)

```

This gives strong indication that the more complete model is better. For completeness' sake,
we'll also compare the model with register operationalized via dimension scores with one that
uses ICE text categories as predictors instead. We only have area under the ROC and AIC to work
with, since the models are not nested:

```{r reg-model-comparison, message=FALSE, warning=FALSE}
cat_reduced2 <- glmmTMB(complpattern ~ country + tenseMatrix +
                          compVerbType + compVerbSem +
                          category +
                          (1|lemmaMatrix) + (1|lemmaComp), 
                        data=VComp, family=binomial)

Preds <- predict(cat_reduced2, type = 'response')
auc(VComp$complpattern, Preds)
AIC(cat_reduced2)
```

With all models given their fair consideration, the best one including (relevant) dimension
scores is the overall winner.

## Quantifying variable importances

To compare the importance of individual predictors in the model, I have adapted the source code
of Jason Grafmiller's permute.varimp() function to work with glmmTMB models. The original code
is part of the JGmermod package (https://rdrr.io/github/jasongraf1/JGmermod/). Careful: this is a bootstrap method that will take a long time to run.

```{r varimps, message=FALSE, warning=FALSE}
permute.varimp <- function(fit, data = NULL, verbose = FALSE, ranef = TRUE){
  require(lme4, quietly = T)
  require(Hmisc, quietly = T)
  require(MuMIn, quietly = T)
  require(glmmTMB, quietly = T)
  
  if (class(fit)[1] %in% c("lmerMod", "glmerMod")){
    y <- fit@resp$y
    data <- as.data.frame(fit@frame)
    if (ranef){
      random <- names(ranef(fit))
      vars <- colnames(attr(attr(fit@frame, "terms"), "factors"))
    } else {
      # only fixed effs
      vars <- strsplit(toString(attr(attr(fit@frame, "terms"),
                                     "predvars.fixed")), ', ')[[1]][-c(1:2)]
    }
  } else if (class(fit)=="glmmTMB"){
    y = as.numeric(fit$frame$complpattern) -1
    data <- as.data.frame(fit$frame)
    random <- names(ranef(fit)$con)
    vars <- attr(terms(reg), "term.labels")
  } else if (class(fit)[1] == "lrm"){
    vars <- colnames(attr(f.lrm$terms, "factors"))
    if(is.null(fit$y)) {
      stop("Must specify lrm(..., y = T) when fitting lrm().")
    } else {
      y <- as.numeric(fit$y) - 1
    }
    if(is.null(data)) stop("Must specify data when using lrm().")
    ranef <- FALSE
  } else if (class(fit)[1] == "glm"){
    data <- fit$data
    vars <- colnames(attr(attr(fit$model, "terms"), "factors"))
    y <- as.numeric(fit$y)
    ranef <- FALSE
  } else {
    stop("fit is not a supported class")
  }
  # remove interaction terms
  vars <- vars[grep(":", vars, invert = T)]
  # add random effects terms to list
  if(ranef) vars <- c(vars, random)
  # get predictions from full model
  full.probs <- predict(fit, type = "response")
  full.C <- somers2(full.probs, y)[[1]]
  full.acc <- mean(round(full.probs) == y)
  full.AICc <- MuMIn::AICc(fit)
  varimp_mat <- matrix(nrow = length(vars), ncol = 3)
  if (verbose) {cat("variables run:\n")}
  # loop through (fixed effects) predictors
  for (i in seq(1, length(vars))){
    # find main effect and any interactions
    d <- data
    d[, vars[i]] <- sample(data[, vars[i]]) # reshuffle values
    if (class(fit)[1] == "glmerMod"){
      # Make sure the updated model inherits the control settings from original
      ctrl = glmerControl(optimizer = fit@optinfo$optimizer,
                          optCtrl = fit@optinfo$control)
      new_fit <- update(fit, data = d, control = ctrl)
    } else if (class(fit)[1] == "lmerMod") {
      # Make sure the updated model inherits the control settings from original
      ctrl = lmerControl(optimizer = fit@optinfo$optimizer,
                         optCtrl = fit@optinfo$control)
      new_fit <- update(fit, data = d, control = ctrl)
    } else {
      new_fit <- update(fit, data = d)
    }
    new.probs <- predict(new_fit, type = "response")
    
    if (class(fit)[1] %in% c("lmerMod", "glmerMod")){
      new_y <- new_fit@resp$y
    } else if (class(fit) == "glmmTMB") {
      new_y <- as.numeric(new_fit$frame$complpattern) -1
    } else {
      new_y <- new_fit$y
    }
    new.C <- somers2(new.probs, new_y)[[1]]
    C.diff <- full.C - new.C
    new.acc <- mean(round(new.probs) == new_y)
    Acc.diff <- full.acc - new.acc
    new.AICc <- MuMIn::AICc(new_fit)
    # The difference in AICc here is the same as the likelihood ratio
    AICc.diff <- new.AICc - full.AICc
    varimp_mat[i, ] <- c(C.diff, Acc.diff, AICc.diff)
    if (verbose) {cat(vars[i], "... ", sep = "")}
  }
  rownames(varimp_mat) <- vars
  colnames(varimp_mat) <- c("C", "accuracy", "AICc")
  return(as.data.frame(varimp_mat))
}
varimps <- permute.varimp(reg)
varimps$predictor <- rownames(varimps)
varimps[varimps$predictor=="PA1",]$predictor = "Involved versus Informational"
varimps[varimps$predictor=="PA2",]$predictor = "Collaborative communication"
varimps[varimps$predictor=="PA4",]$predictor = "Explicit stance-marking"
varimps[varimps$predictor=="PA5",]$predictor = "Situational anchoring"
varimps[varimps$predictor=="PA9",]$predictor = "Assertion of factual validity"
varimps[varimps$predictor=="PA10",]$predictor = "Addressee-orientation"
varimps$predictor <- as.factor(varimps$predictor)
plot_imps <- varimps %>% filter(!predictor %in% names(ranef(reg)$con))
varimps_gg <- ggplot(plot_imps) + 
  geom_col(aes(x=reorder(predictor, AICc), y= AICc, fill=predictor)) + 
  scale_fill_manual(values=c(rep("grey20", 3), rep("grey70", 2), "grey50", rep("grey20", 3), "grey70")) +
  coord_flip() +
  theme_bw() +
  theme(legend.position="none",
        axis.title.y=element_blank(),
        axis.text=element_text(size=12, face="bold"),
        axis.title.x =element_text(size=20, face="bold"))
varimps_gg
ggsave("Figure1.svg", varimps_gg, device = "svg", width = 240, height= 160, units = "mm",dpi = 300)
```

## Coefficient plots

Let's plot the coefficient estimates for the two models with and without dimension scores, with
as specific eye towards the country-level coefficients in each.

```{r coefplots, message=FALSE, warning=FALSE}
#Solve issues with re-ordering variables; solution adapted from https://github.com/fsolt/dotwhisker/issues/72
order_vars_original <- c("countryIE","countryNZ", "countryUSA", "countryCA",
                         "countryJA", "countrySG", "countryPH",
                         "countryHK", "countryIN",
                         "PA1", "PA2", "PA4", "PA5", "PA7", "PA9", "PA10")

### A custom "not in" operator to make subsetting the variables easier
'%!in%' <- function(x,y)!('%in%'(x,y))

data_plot <- rbind(broom::tidy(noreg) %>%  mutate(model = "Model 1: Without dimension scores"),
                   broom::tidy(reg) %>%  mutate(model = "Model 2: Dimension scores included")) %>% 
  filter(effect == "fixed") %>%
  filter(term != "(Intercept)") %>%
  filter(grepl("(country|PA)", term)) %>%
  mutate(term = factor(term, levels = order_vars_original)) %>%
  relabel_predictors(c(countryCA = "CANADA",
                       countryIE = "IRELAND",
                       countryNZ ="NEW ZEALAND",
                       countryUSA = "USA",
                       countryJA = "JAMAICA",
                       countrySG = "SINGAPORE",
                       countryPH = "PHILIPPINES",
                       countryHK = "HONG KONG",
                       countryIN = "INDIA",
                       PA1 = "Involved versus Informational",
                       PA2 = "Collaborative communication",
                       PA4 = "Explicit stance-marking",
                       PA5 = "Situational anchoring",
                       PA9 = "Assertion of factual validity",
                       PA10 = "Addressee-orientation"))

two_brackets <- list(c("Country", "CANADA", "INDIA"), 
                 c("Dimension", "Involved versus Informational", "Addressee-orientation"))

## Only use each option once (e.g. theme) and improve structure
Fig2 <- dwplot(data_plot, dodge_size = 0.4, whisker_args = list(aes(linetype = model))) +
  theme_bw() + 
  ggtitle("Predictors of verb complementation choice") + 
  xlab("Coefficient Estimate") + 
  ylab("") + 
  xlim(-1.2,0.5) + 
  geom_vline(xintercept = 0, colour="grey60", linetype=2) + 
  #theme(legend.position = "none") +
  annotate("pointrange", x = -1.14, y = 4.4, xmin=-1.19, xmax=-1.09, size = 0.3, col="grey60") + 
  annotate("text", x = -1.05, y = 4.4, size = 2.5, hjust = 0, label = "Model without register: C-value = 0.91, AIC = 8153", col="grey50") + 
  annotate("pointrange", x = -1.14, y = 5, xmin=-1.19, xmax=-1.09, size = 0.3, col="grey20", lty=2) + 
  annotate("text", x = -1.05, y = 5, size = 2.5, hjust = 0, label = "Model with register: C-value = 0.92, AIC = 7900", col="grey30") + 
  annotate("text", x = -1.19, y = 2.5, size = 2.5, hjust = 0,
           label = "Fixed effects not plotted:\n- matrix verb tense\n- complement verb type\n- complement verb semantics",
           col="grey40") + 
  annotate("rect", xmin = -1.2, xmax = -0.4, ymin = 1, ymax = 6, alpha = .1) +
  scale_color_manual(values=c("grey60", "grey20")) +
  theme(axis.text.y = element_text(size = 11), 
        axis.text.x = element_text(size = 12), 
        axis.title=element_text(size=14),
        plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
        legend.position = "none",
        #legend.title = element_blank(),
        #legend.text = element_text(size=14),
        panel.grid.minor.y = element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.x = element_blank(), 
        panel.grid.major.x=element_blank())
ggsave("Figure2.svg", Fig2, device = "svg", width = 240, height= 160, units = "mm",dpi = 300)
```

## Calculating country coefficient distance matrices

To further illustrate how the two models create an "inter-variety space of variation", we
can project the individual varieties/countries into a 2-dimensional space via multi-dimensional
scaling. For this, we create a pairwise distance matrix on the basis of the coefficient estimates and use this matrix for the MDS projection.

```{r MDS-noreg, message=FALSE, warning=FALSE}
noreg_country <- tidy(noreg) %>% 
  filter(grepl("country", term)) %>%
  dplyr::select(term, estimate)
noreg_country_full <- rbind(noreg_country, c(term="countryGB", estimate=0))
rownames(noreg_country_full) <- c("CANADA","HONG KONG","IRELAND","INDIA","JAMAICA","NEW ZEALAND","PHILIPPINES","SINGAPORE","USA","GB")
noreg_dis <- dist(noreg_country_full)
noreg_mds <- noreg_dis %>%
  cmdscale() %>%
  as_tibble()
colnames(noreg_mds) <- c("Dim.1", "Dim.2")

ggscatter(noreg_mds, x = "Dim.1", y = "Dim.2", 
          label = rownames(noreg_country_full), repel=T)
```

```{r MDS-reg, message=FALSE, warning=FALSE}
reg_country <- tidy(reg) %>% 
  filter(grepl("country", term)) %>%
  dplyr::select(term, estimate)
reg_country_full <- rbind(reg_country, c(term="countryGB", estimate=0))
rownames(reg_country_full) <- c("CANADA","HONG KONG","IRELAND","INDIA","JAMAICA","NEW ZEALAND",
                                "PHILIPPINES","SINGAPORE","USA","GB")
reg_dis <- dist(reg_country_full)
reg_mds <- reg_dis %>%
  cmdscale() %>%
  as_tibble()
colnames(reg_mds) <- c("Dim.1", "Dim.2")
ggscatter(reg_mds, x = "Dim.1", y = "Dim.2",
          label = rownames(reg_country_full), repel=T)
```

For a final overview plot, we superimpose the two MDS solutions over each other. We also visualize the differences in country-coefficient relationships by means of hierarchical clustering. This is exploratory, but given that such clustering methods are used to project
relationships among varieties in the literature (e.g. Szmrecsanyi 2013; Szmrecsanyi et al. 2019), it gives a good sense of the impact of including register in studies of the kind we are interested in here.

```{r MDS-dendro, message=FALSE, warning=FALSE}
reg_mds$model <-"Model 2: Including dimension scores"
noreg_mds$model <-"Model 1: Without dimension scores"
noreg_mds$country <-rownames(noreg_country_full)
reg_mds$country <-rownames(reg_country_full)
mds_com <- rbind(reg_mds, noreg_mds)
ggscatter(mds_com, x = "Dim.1", y = "Dim.2", color = "model",
          label = "country", palette= c("grey60", "grey20"), repel=T)


p1 <- ggscatter(mds_com, x = "Dim.1", y = "Dim.2", color = "model",
                label = "country", palette= c("grey60", "grey20"), repel=T, 
                size=4, font.label = c(10, "plain")) +
  theme_article() +
  labs(fill = "") +
  theme(plot.title = element_text(size=13, hjust=0.5),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.x=element_blank(),
        legend.title=element_blank(),
        legend.position = "top") +
  ggtitle("MDS projection of relationships between varieties")

p2 <- ggdendrogram(hclust(noreg_dis, method="ward.D2"), colour="grey50") + 
  theme_article() +
  theme(plot.title = element_text(size=13, hjust=0.5),
        axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_text(angle=90),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank(),
        plot.margin=margin(10,10,10,10)) +
  ggtitle("Dendrogram Model 1")
p3 <- ggdendrogram(hclust(reg_dis, method="ward.D2")) +
  theme_article() +
  theme(plot.title = element_text(size=13, hjust=0.5),
        axis.line.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.y=element_blank(),
        axis.title.y=element_blank(),
        axis.title.x=element_blank(),
        axis.text.x= element_text(angle=90),
        panel.background=element_rect(fill="white"),
        panel.grid=element_blank(),
        plot.margin=margin(10,10,10,10)) +
  ggtitle("Dendrogram Model 2")
lay <- rbind(c(1,1,1,1,2,2),
             c(1,1,1,1,2,2),
             c(1,1,1,1,3,3),
             c(1,1,1,1,3,3))
Fig3 <- grid.arrange(grobs=list(p1,p2,p3),layout_matrix = lay)
ggsave("Figure3.svg", Fig3, device = "svg", width = 240, height= 160, units = "mm",dpi = 300)
```

## Mantel test to compare the two distance matrices

For a formalized test of the difference between the two distance matrices, we can turn to
the Mantel test, which is an extension of correlation tests (Pearson, Spearman, etc.) to matrices by means of permutation tests. This is not a very well specified test, but it is the
best stab at the data I can think of here.

```{r Mantel, message=FALSE, warning=FALSE}
mantel(reg_dis, noreg_dis, method="pearson")
```
